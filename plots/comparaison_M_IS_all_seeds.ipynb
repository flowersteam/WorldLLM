{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "print(\"-------------------------------- Load IS --------------------------------\")\n",
    "experiment_ext = \"\"\n",
    "name_experiment_is = \"playground_is_phi_phi\" + experiment_ext\n",
    "path_start = \"../outputs/\" + name_experiment_is + \"/\"\n",
    "lst_data_is = []\n",
    "for f_day in os.listdir(path_start):\n",
    "    if os.path.isdir(path_start + f_day):\n",
    "        for f_hour in os.listdir(path_start + f_day):\n",
    "            if os.path.isdir(path_start + f_day + \"/\" + f_hour):\n",
    "                path = path_start + f_day + \"/\" + f_hour + \"/all.json\"\n",
    "                with open(path, \"r\") as file:\n",
    "                    lst_data_is.append(json.load(file))\n",
    "                    print(\"Loaded: \" + path)\n",
    "print(\"-------------------------------- Load Metropolis --------------------------------\")\n",
    "name_experiment_m = \"/playground_metropolis_phi_phi\"\n",
    "path_start = \"../outputs/\" + name_experiment_m + \"/\"\n",
    "lst_data_m = []             \n",
    "for f_day in os.listdir(path_start):\n",
    "    if os.path.isdir(path_start + f_day):\n",
    "        for f_hour in os.listdir(path_start + f_day):\n",
    "            if os.path.isdir(path_start + f_day + \"/\" + f_hour):\n",
    "                path = path_start + f_day + \"/\" + f_hour + \"/all.json\"\n",
    "                with open(path, \"r\") as file:\n",
    "                    lst_data_m.append(json.load(file))\n",
    "                    print(\"Loaded: \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fair comparison it is better to compare with the same true rule\n",
    "true_rule = lst_data_m[0][\"true_rules\"]\n",
    "for data in lst_data_m + lst_data_is:\n",
    "    assert data[\"true_rules\"] == true_rule\n",
    "    print(len(data[\"rules\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct all rules IS\n",
    "all_rules_is = []\n",
    "all_likelihoods_is = []\n",
    "all_weights_is = []\n",
    "for data in lst_data_is:\n",
    "    all_rules_is.append(np.repeat(data[\"rules\"], data[\"metrics\"][\"counts\"]))\n",
    "    all_likelihoods_is.append(np.repeat(data[\"metrics\"][\"test_likelihoods\"], data[\"metrics\"][\"counts\"]))\n",
    "    all_weights_is.append(np.repeat(data[\"metrics\"][\"weights\"], data[\"metrics\"][\"counts\"]))\n",
    "all_rules_is = np.stack(all_rules_is)\n",
    "all_likelihoods_is = np.stack(all_likelihoods_is)\n",
    "all_weights_is = np.stack(all_weights_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct all rules Metropolis\n",
    "all_rules_m = []\n",
    "all_likelihoods_m = []\n",
    "all_weights_m = []\n",
    "all_prev_rules_ind_m = []\n",
    "for data in lst_data_m:\n",
    "    nb_particles = data[\"metrics\"][\"nb_rules\"]\n",
    "    rules = np.array(data[\"rules\"])\n",
    "    likelihoods = np.array(data[\"metrics\"][\"test_likelihoods\"])\n",
    "    weights =  np.array(data[\"metrics\"][\"weights\"])\n",
    "    prev_rules_ind = np.array(data[\"metrics\"][\"prev_rules_ind\"])\n",
    "    all_rules_m.append(rules.reshape((-1, nb_particles)).transpose())\n",
    "    all_likelihoods_m.append(likelihoods.reshape((-1, nb_particles)).transpose())\n",
    "    all_weights_m.append(weights.reshape((-1, nb_particles)).transpose())\n",
    "    all_prev_rules_ind_m.append(prev_rules_ind.reshape((-1, nb_particles)).transpose())\n",
    "# Concatenate all seeds\n",
    "all_rules_m = np.concatenate(all_rules_m, axis=0)\n",
    "all_likelihoods_m = np.concatenate(all_likelihoods_m, axis=0)\n",
    "all_weights_m = np.concatenate(all_weights_m, axis=0)\n",
    "all_prev_rules_ind_m = np.concatenate(all_prev_rules_ind_m, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the likelihood without the rule for each seed in IS:\n",
    "for i in range(len(all_rules_is)):\n",
    "    assert (all_rules_is[i][-1]) is None\n",
    "    print(f\"For seed {i} the likelihood without the rule is {all_likelihoods_is[i][-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare best rule for IS and Metripolis\n",
    "# Best rules of each method\n",
    "best_taken = 50\n",
    "best_rules_ind_m = np.argsort(-all_likelihoods_m.flatten())[:best_taken]\n",
    "best_rules_ind_is = np.argsort(-all_likelihoods_is.flatten())[:best_taken]\n",
    "all_likelihoods = np.concatenate([all_likelihoods_m.flatten()[best_rules_ind_m], all_likelihoods_is.flatten()[best_rules_ind_is]])\n",
    "all_rules = np.concatenate([all_rules_m.flatten()[best_rules_ind_m], all_rules_is.flatten()[best_rules_ind_is]])\n",
    "indices = np.argsort(-all_likelihoods)\n",
    "print(f\"Best rules for Metropolis in red and for IS in green\")\n",
    "for incr, ind in enumerate(indices):\n",
    "    if ind < best_taken:\n",
    "        color_start = \"\\033[31m\"\n",
    "        color_end = \"\\033[0m\"\n",
    "    else:\n",
    "        color_start = \"\\033[92m\"\n",
    "        color_end = \"\\033[0m\"\n",
    "    print(\n",
    "        f\"{color_start}-----rule-----:{incr}: {repr(all_rules[ind])}, likelihood: {all_likelihoods[ind]:2f}{color_end}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sames rules per particle\n",
    "lst_nb_redundant_rules_m = []\n",
    "for particle in all_rules_m:\n",
    "    lst_nb_redundant_rules_m.append(len(particle) - len(set(particle)))\n",
    "lst_nb_redundant_rules_is = []\n",
    "for particle in all_rules_is:\n",
    "    lst_nb_redundant_rules_is.append(len(particle) - len(set(particle))\n",
    ")\n",
    "print(\"Redundant rules per particle for Metropolis: \", lst_nb_redundant_rules_m)\n",
    "print(\"Redundant rules per particle for IS: \", lst_nb_redundant_rules_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot violin plot of the log likelihood as a function of the seeds for both algorithms\n",
    "plt.figure()\n",
    "color_m = plt.violinplot(all_likelihoods_m.transpose(), showmeans=True, side = \"low\")[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_m = matplotlib.patches.Patch(color=color_m)\n",
    "color_is = plt.violinplot(all_likelihoods_is.transpose(), showmeans=True, side=\"high\", positions=[i+1.03 for i in range(len(all_likelihoods_is))])[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_is = matplotlib.patches.Patch(color=color_is)\n",
    "plt.legend([color_m, color_is], [\"M\", \"IS\"])\n",
    "plt.title(\"Violin plot of the log likelihood for the differents seeds\")\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Log likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot violin plot of the log likelihood as a function of the seeds for both algorithms\n",
    "fig,ax = plt.subplots()\n",
    "color_m = plt.violinplot(all_likelihoods_m.transpose(), showmeans=True, side = \"low\")[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_m = matplotlib.patches.Patch(color=color_m)\n",
    "color_is = plt.violinplot(all_likelihoods_is.transpose(), showmeans=True, side=\"high\", positions=[i+1.03 for i in range(len(all_likelihoods_is))])[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_is = matplotlib.patches.Patch(color=color_is)\n",
    "ax.set_ylim(-20,0)\n",
    "plt.legend([color_m, color_is], [\"M\", \"IS\"])\n",
    "plt.title(\"Violin plot of the log likelihood for the differents seeds\")\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Log likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot violin plot of the log likelihood as a function of the seeds for both algorithms for high likelihoods\n",
    "min_likelihood=-np.inf\n",
    "high_likelihoods_m = [all_likelihoods_m[row][all_likelihoods_m[row] > min_likelihood] for row in range(len(all_likelihoods_m))]\n",
    "high_likelihoods_is = [all_likelihoods_is[row][all_likelihoods_is[row] > min_likelihood] for row in range(len(all_likelihoods_is))]\n",
    "fig,ax = plt.subplots()\n",
    "color_m = plt.violinplot(high_likelihoods_m, showmeans=True, side = \"low\")[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_m = matplotlib.patches.Patch(color=color_m)\n",
    "color_is = plt.violinplot(high_likelihoods_is, showmeans=True, side=\"high\")[\"bodies\"][0].get_facecolor().flatten()\n",
    "color_is = matplotlib.patches.Patch(color=color_is)\n",
    "plt.legend([color_m, color_is], [\"M\", \"IS\"])\n",
    "plt.title(\"Violin plot of the log likelihood for the differents seeds\")\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Log likelihood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = model.encode(np.concatenate([all_rules_m.flatten(), all_rules_is.flatten()], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the t-SNE embeddings\n",
    "proj_embeddings = TSNE(n_components=2).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(proj_embeddings[len(all_rules_m.flatten()):,0], proj_embeddings[len(all_rules_m.flatten()):,1], label=\"IS\")\n",
    "#Plot m particles\n",
    "for i in range(all_rules_m.shape[0]):\n",
    "    plt.scatter(proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],0], proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],1], label=\"M particle \"+str(i))\n",
    "plt.legend()\n",
    "plt.xlabel(\"TSNE 1\")\n",
    "plt.ylabel(\"TSNE 2\")\n",
    "plt.title(\"TSNE of the rules depending on the generation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings\n",
    "plt.figure(figsize=(15,10))\n",
    "for i in range(4):\n",
    "    plt.scatter(proj_embeddings[len(all_rules_m.flatten()) +i*all_rules_is.shape[1]: len(all_rules_m.flatten()) +(i+1)*all_rules_is.shape[1],0], proj_embeddings[len(all_rules_m.flatten()) +i*all_rules_is.shape[1]: len(all_rules_m.flatten()) +(i+1)*all_rules_is.shape[1],1], label=\"IS particle \"+str(i))\n",
    "# plt.scatter(proj_embeddings[len(all_rules_m.flatten()):,0], proj_embeddings[len(all_rules_m.flatten()):,1], label=\"IS\")\n",
    "#Plot Metropolis particles\n",
    "for i in range(4):\n",
    "    plt.scatter(proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],0], proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],1], label=\"M particle \"+str(i))\n",
    "plt.legend()\n",
    "plt.xlabel(\"TSNE 1\")\n",
    "plt.ylabel(\"TSNE 2\")\n",
    "plt.title(\"TSNE of the rules depending on the generation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot embeddings with likelihoods high enough\n",
    "# Plot the embeddings\n",
    "all_likelihoods = np.concatenate([all_likelihoods_m.flatten(), all_likelihoods_is.flatten()])\n",
    "mask_likelihood = all_likelihoods > -300\n",
    "mask_is = np.arange(len(all_likelihoods)) >= len(all_rules_m.flatten())\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(proj_embeddings[mask_likelihood&mask_is,0], proj_embeddings[mask_likelihood&mask_is,1], label=\"IS\")\n",
    "#Plot Metropolis particles\n",
    "for i in range(len(all_rules_m)):\n",
    "    mask_m = (np.arange(len(all_likelihoods)) < (i+1)*all_rules_m.shape[1]) & (np.arange(len(all_likelihoods)) >= i*all_rules_m.shape[1])\n",
    "    plt.scatter(proj_embeddings[mask_likelihood&mask_m,0], proj_embeddings[mask_likelihood&mask_m,1], label=\"M particle \"+str(i))\n",
    "plt.legend()\n",
    "plt.xlabel(\"TSNE 1\")\n",
    "plt.ylabel(\"TSNE 2\")\n",
    "plt.title(\"TSNE of the rules depending on the generation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the PCA embeddings\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "proj_embeddings = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the embeddings\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(proj_embeddings[len(all_rules_m.flatten()):,0], proj_embeddings[len(all_rules_m.flatten()):,1], label=\"IS\")\n",
    "#Plot Metropolis particles\n",
    "for i in range(len(all_rules_m)):\n",
    "    plt.scatter(proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],0], proj_embeddings[i*all_rules_m.shape[1]: (i+1)*all_rules_m.shape[1],1], label=\"M particle \"+str(i))\n",
    "plt.legend()\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.title(\"PCA of the rules depending on the generation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot embeddings with likelihoods high enough\n",
    "# Plot the embeddings\n",
    "all_likelihoods = np.concatenate([all_likelihoods_m.flatten(), all_likelihoods_is.flatten()])\n",
    "mask_likelihood = all_likelihoods > -400\n",
    "mask_is = np.arange(len(all_likelihoods)) >= len(all_rules_m.flatten())\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(proj_embeddings[mask_likelihood&mask_is,0], proj_embeddings[mask_likelihood&mask_is,1], label=\"IS\")\n",
    "#Plot Metropolis particles\n",
    "for i in range(len(all_rules_m)):\n",
    "    mask_m = (np.arange(len(all_likelihoods)) < (i+1)*all_rules_m.shape[1]) & (np.arange(len(all_likelihoods)) >= i*all_rules_m.shape[1])\n",
    "    plt.scatter(proj_embeddings[mask_likelihood&mask_m,0], proj_embeddings[mask_likelihood&mask_m,1], label=\"M particle \"+str(i))\n",
    "plt.legend()\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.title(\"PCA of the rules depending on the generation\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
